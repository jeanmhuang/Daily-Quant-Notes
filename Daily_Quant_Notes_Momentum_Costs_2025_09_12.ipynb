{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanmhuang/Daily-Quant-Notes/blob/main/Daily_Quant_Notes_Momentum_Costs_2025_09_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66de5f49",
      "metadata": {
        "id": "66de5f49"
      },
      "source": [
        "# Daily Quant Notes — Transaction Cost Sensitivity for Momentum\n",
        "**Date:** 2025-09-12\n",
        "\n",
        "This notebook builds a simple cross-sectional momentum strategy and studies how transaction costs (slippage/commissions) erode returns under realistic assumptions. It is designed to be short, reproducible, and portfolio-relevant for interviews with hedge funds and banks.\n",
        "\n",
        "**What you'll do:**\n",
        "1. Download liquid U.S. equities data (S&P 100 by default).\n",
        "2. Construct a monthly-rebalanced momentum signal (12–1 months lookback; configurable).\n",
        "3. Form long-only and long–short decile portfolios.\n",
        "4. Apply a simple transaction cost model per turnover.\n",
        "5. Compare gross vs. net performance across cost assumptions.\n",
        "6. Report key statistics (CAGR, Sharpe, max drawdown, turnover).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ce5a7b5",
      "metadata": {
        "id": "6ce5a7b5"
      },
      "source": [
        "## 0. Setup\n",
        "Run this cell to install/import dependencies. (Colab users: the installs are included.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd660489",
      "metadata": {
        "id": "dd660489"
      },
      "outputs": [],
      "source": [
        "\n",
        "# If you're on Colab, uncomment the following line to install yfinance and pandas_ta if needed:\n",
        "# !pip install yfinance pandas_ta --quiet\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
        "pd.options.display.float_format = \"{:,.6f}\".format\n",
        "\n",
        "print(\"Versions -> pandas:\", pd.__version__, \"| numpy:\", np.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53da6806",
      "metadata": {
        "id": "53da6806"
      },
      "source": [
        "## 1. Parameters\n",
        "Adjust your universe, dates, and strategy hyperparameters here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "193d7147",
      "metadata": {
        "id": "193d7147"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Universe: default to S&P 100 tickers (static list for reproducibility) ---\n",
        "SP100 = [\n",
        "    \"AAPL\",\"ABBV\",\"ABT\",\"ACN\",\"ADBE\",\"AIG\",\"AMD\",\"AMGN\",\"AMT\",\"AMZN\",\"AVGO\",\"AXP\",\n",
        "    \"BA\",\"BAC\",\"BMY\",\"BK\",\"BKNG\",\"BLK\",\"C\",\"CAT\",\"CHTR\",\"CL\",\"CMCSA\",\"COF\",\"COP\",\n",
        "    \"COST\",\"CRM\",\"CSCO\",\"CVS\",\"CVX\",\"DHR\",\"DIS\",\"DOW\",\"DUK\",\"EMR\",\"EXC\",\"F\",\"FDX\",\n",
        "    \"GD\",\"GE\",\"GILD\",\"GM\",\"GOOG\",\"GOOGL\",\"GS\",\"HD\",\"HON\",\"IBM\",\"INTC\",\"JNJ\",\"JPM\",\n",
        "    \"KO\",\"LIN\",\"LLY\",\"LMT\",\"LOW\",\"MA\",\"MCD\",\"MDLZ\",\"MDT\",\"META\",\"MET\",\"MMM\",\"MO\",\n",
        "    \"MRK\",\"MS\",\"MSFT\",\"NEE\",\"NFLX\",\"NKE\",\"NVDA\",\"ORCL\",\"PEP\",\"PFE\",\"PG\",\"PM\",\"QCOM\",\n",
        "    \"RTX\",\"SBUX\",\"SO\",\"SPG\",\"T\",\"TGT\",\"TMO\",\"TMUS\",\"TSLA\",\"TXN\",\"UNH\",\"UNP\",\"UPS\",\n",
        "    \"USB\",\"V\",\"VZ\",\"WBA\",\"WFC\",\"WMT\",\"XOM\"\n",
        "]\n",
        "\n",
        "params = {\n",
        "    \"tickers\": SP100,              # universe\n",
        "    \"start\": \"2005-01-01\",         # backtest start\n",
        "    \"end\": None,                   # None = today\n",
        "    \"rebalance_freq\": \"M\",         # monthly\n",
        "    \"lookback_months\": 12,         # momentum lookback length (months)\n",
        "    \"skip_recent_months\": 1,       # skip most-recent month (12-1 momentum)\n",
        "    \"top_decile\": 0.10,            # long decile threshold\n",
        "    \"bottom_decile\": 0.10,         # short decile threshold\n",
        "    \"cost_grid_bps\": [0, 5, 10, 25, 50, 100],  # round-trip cost in basis points\n",
        "    \"min_price\": 5.0,              # filter penny/illiquid names (optional heuristic)\n",
        "    \"dropna_thresh\": 0.80          # require >=80% data coverage per ticker\n",
        "}\n",
        "params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6307e1c9",
      "metadata": {
        "id": "6307e1c9"
      },
      "source": [
        "## 2. Data\n",
        "We use **adjusted close** from Yahoo Finance via `yfinance`. For liquidity sanity, we can drop names with too many missing values and impose a minimum price filter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff139eaf",
      "metadata": {
        "id": "ff139eaf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def download_prices(tickers, start, end=None):\n",
        "    \"\"\"Download Adjusted Close prices with yfinance.\"\"\"\n",
        "    data = yf.download(tickers, start=start, end=end, auto_adjust=False, progress=False)[\"Adj Close\"]\n",
        "    # If a single ticker is passed, yfinance returns a Series -> convert to DataFrame\n",
        "    if isinstance(data, pd.Series):\n",
        "        data = data.to_frame()\n",
        "    return data.sort_index()\n",
        "\n",
        "prices = download_prices(params[\"tickers\"], params[\"start\"], params[\"end\"])\n",
        "\n",
        "# Liquidity/quality filters\n",
        "coverage = prices.notna().mean()\n",
        "keep = coverage[coverage >= params[\"dropna_thresh\"]].index.tolist()\n",
        "prices = prices[keep]\n",
        "\n",
        "# Filter by minimum price (using last price)\n",
        "last_px = prices.ffill().iloc[-1]\n",
        "keep2 = last_px[last_px >= params[\"min_price\"]].index.tolist()\n",
        "prices = prices[keep2]\n",
        "\n",
        "print(f\"Final universe size: {prices.shape[1]} tickers\")\n",
        "prices.tail().head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f2a0a37",
      "metadata": {
        "id": "8f2a0a37"
      },
      "source": [
        "## 3. Momentum Signal (12–1 months by default)\n",
        "Classical cross-sectional momentum: rank stocks by trailing returns over `lookback_months`, skipping the most recent `skip_recent_months` to avoid short-term mean reversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "246d858a",
      "metadata": {
        "id": "246d858a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def resample_month_end(df):\n",
        "    return df.resample(\"M\").last()\n",
        "\n",
        "def compute_mom_signal(prices_m, lookback, skip):\n",
        "    # compute trailing returns from t-(lookback+skip) to t-skip\n",
        "    ret = prices_m.pct_change().add(1).cumprod()\n",
        "    # shift by 'skip' months so the window ends skip months ago\n",
        "    ret_shifted = ret.shift(skip)\n",
        "    # momentum = trailing return over lookback window\n",
        "    mom = ret_shifted / ret_shifted.shift(lookback) - 1.0\n",
        "    return mom\n",
        "\n",
        "prices_m = resample_month_end(prices.ffill())\n",
        "momentum = compute_mom_signal(prices_m, params[\"lookback_months\"], params[\"skip_recent_months\"])\n",
        "momentum = momentum.dropna(how=\"all\")\n",
        "momentum.tail().head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee23074d",
      "metadata": {
        "id": "ee23074d"
      },
      "source": [
        "## 4. Portfolio Construction\n",
        "- **Long-only Top Decile**: equally-weight top `p` fraction by momentum each month.\n",
        "- **Long–Short (Top–Bottom)**: long top decile, short bottom decile, market-neutral.\n",
        "We compute **monthly portfolio returns** and track **turnover** (for costs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda40917",
      "metadata": {
        "id": "eda40917"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_weights_from_ranks(scores, top_frac=0.10, bottom_frac=0.10, long_short=False):\n",
        "    weights = pd.DataFrame(index=scores.index, columns=scores.columns, data=0.0)\n",
        "    for date, row in scores.iterrows():\n",
        "        valid = row.dropna()\n",
        "        if valid.empty:\n",
        "            continue\n",
        "        n = len(valid)\n",
        "        k_top = max(1, int(math.floor(n * top_frac)))\n",
        "        winners = valid.sort_values(ascending=False).head(k_top).index.tolist()\n",
        "\n",
        "        if long_short:\n",
        "            k_bot = max(1, int(math.floor(n * bottom_frac)))\n",
        "            losers = valid.sort_values(ascending=True).head(k_bot).index.tolist()\n",
        "            w = pd.Series(0.0, index=row.index)\n",
        "            if k_top > 0:\n",
        "                w.loc[winners] =  1.0 / k_top\n",
        "            if k_bot > 0:\n",
        "                w.loc[losers]  = -1.0 / k_bot\n",
        "            weights.loc[date] = w\n",
        "        else:\n",
        "            w = pd.Series(0.0, index=row.index)\n",
        "            if k_top > 0:\n",
        "                w.loc[winners] = 1.0 / k_top\n",
        "            weights.loc[date] = w\n",
        "\n",
        "    return weights\n",
        "\n",
        "def compute_portfolio_returns(prices_m, weights):\n",
        "    \"\"\"Next-month returns of current weights (assumes rebalancing at month-end close).\"\"\"\n",
        "    rets = prices_m.pct_change().shift(-1)  # next month forward return\n",
        "    port_ret = (weights * rets).sum(axis=1)\n",
        "    port_ret = port_ret.dropna()\n",
        "    return port_ret\n",
        "\n",
        "def compute_turnover(weights):\n",
        "    \"\"\"Sum of absolute weight changes at each rebalance (L1), divided by 2 for one-way turnover.\"\"\"\n",
        "    dW = (weights - weights.shift(1)).abs()\n",
        "    # For long-only, L1/2 is conventional one-way turnover; for long-short, L1 may be used.\n",
        "    turnover = dW.sum(axis=1) / 2.0\n",
        "    return turnover.fillna(0.0)\n",
        "\n",
        "# Align scores to month-end dates present in prices_m\n",
        "scores = momentum.loc[prices_m.index.intersection(momentum.index)]\n",
        "w_long = make_weights_from_ranks(scores, top_frac=params[\"top_decile\"], long_short=False)\n",
        "w_ls   = make_weights_from_ranks(scores, top_frac=params[\"top_decile\"], bottom_frac=params[\"bottom_decile\"], long_short=True)\n",
        "\n",
        "r_long = compute_portfolio_returns(prices_m, w_long)\n",
        "r_ls   = compute_portfolio_returns(prices_m, w_ls)\n",
        "\n",
        "to_long = compute_turnover(w_long)\n",
        "to_ls   = compute_turnover(w_ls)\n",
        "\n",
        "print(\"Sample:\")\n",
        "print(pd.DataFrame({\n",
        "    \"r_long\": r_long.tail(3),\n",
        "    \"r_ls\"  : r_ls.tail(3),\n",
        "}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b392ffbc",
      "metadata": {
        "id": "b392ffbc"
      },
      "source": [
        "## 5. Transaction Cost Model\n",
        "We apply a **round-trip cost** in basis points per unit turnover. A simple monthly approximation:\n",
        "\n",
        "$$ r^{net}_t = r^{gross}_t - c \\times \\text{turnover}_t $$\n",
        "\n",
        "Where `c` is cost per round-trip in decimal (e.g., 25 bps = 0.0025).\n",
        "This is a stylized model; in reality execution costs depend on spread, volatility, participation rate, and slippage vs. benchmarks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b72fe23",
      "metadata": {
        "id": "5b72fe23"
      },
      "outputs": [],
      "source": [
        "\n",
        "def apply_costs(gross_returns, turnover, cost_bps):\n",
        "    c = cost_bps / 1e4  # convert bps to decimal\n",
        "    # Monthly cost ~ c * turnover\n",
        "    net = gross_returns - c * turnover\n",
        "    return net\n",
        "\n",
        "def perf_stats(returns, rf_annual=0.0):\n",
        "    rd = returns.dropna()\n",
        "    if rd.empty:\n",
        "        return {\"CAGR\": np.nan, \"Sharpe\": np.nan, \"MaxDD\": np.nan, \"Vol\": np.nan}\n",
        "    # CAGR\n",
        "    cum = (1.0 + rd).prod()\n",
        "    years = len(rd) / 12.0\n",
        "    cagr = cum ** (1/years) - 1 if years > 0 else np.nan\n",
        "    # Vol (annualized)\n",
        "    vol = rd.std() * np.sqrt(12)\n",
        "    # Sharpe (assuming rf=0 for simplicity)\n",
        "    sharpe = (rd.mean() * 12) / vol if vol and vol > 0 else np.nan\n",
        "    # Max drawdown\n",
        "    equity = (1.0 + rd).cumprod()\n",
        "    peak = equity.cummax()\n",
        "    dd = (equity / peak - 1.0).min()\n",
        "    return {\"CAGR\": cagr, \"Sharpe\": sharpe, \"MaxDD\": dd, \"Vol\": vol}\n",
        "\n",
        "# Sweep costs\n",
        "cost_grid = params[\"cost_grid_bps\"]\n",
        "results = []\n",
        "\n",
        "for strategy_name, gross, to in [\n",
        "    (\"Long-Only Top Decile\", r_long, to_long),\n",
        "    (\"Long–Short Top–Bottom\", r_ls, to_ls)\n",
        "]:\n",
        "    for bps in cost_grid:\n",
        "        net = apply_costs(gross, to, bps)\n",
        "        stats = perf_stats(net)\n",
        "        stats.update({\"Strategy\": strategy_name, \"Cost_bps\": bps})\n",
        "        results.append(stats)\n",
        "\n",
        "res_df = pd.DataFrame(results)[[\"Strategy\",\"Cost_bps\",\"CAGR\",\"Sharpe\",\"MaxDD\",\"Vol\"]]\n",
        "res_df.sort_values([\"Strategy\",\"Cost_bps\"], inplace=True)\n",
        "res_df.head(12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "372edb0d",
      "metadata": {
        "id": "372edb0d"
      },
      "source": [
        "## 6. Results & Visuals\n",
        "We plot gross vs net equity curves and a sensitivity table for Sharpe/CAGR across cost assumptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6bbd5ef",
      "metadata": {
        "id": "d6bbd5ef"
      },
      "outputs": [],
      "source": [
        "\n",
        "def equity_curve(returns):\n",
        "    return (1.0 + returns.dropna()).cumprod()\n",
        "\n",
        "# Choose a representative cost to visualize\n",
        "viz_bps = 25  # change to taste\n",
        "\n",
        "# Long-only\n",
        "net_long = apply_costs(r_long, to_long, viz_bps)\n",
        "ec_long_g = equity_curve(r_long)\n",
        "ec_long_n = equity_curve(net_long)\n",
        "\n",
        "plt.figure()\n",
        "ec_long_g.plot(label=\"Gross\")\n",
        "ec_long_n.plot(label=f\"Net ({viz_bps} bps)\")\n",
        "plt.title(\"Long-Only Top Decile — Equity Curve\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Growth of $1\")\n",
        "plt.show()\n",
        "\n",
        "# Long–short\n",
        "net_ls = apply_costs(r_ls, to_ls, viz_bps)\n",
        "ec_ls_g = equity_curve(r_ls)\n",
        "ec_ls_n = equity_curve(net_ls)\n",
        "\n",
        "plt.figure()\n",
        "ec_ls_g.plot(label=\"Gross\")\n",
        "ec_ls_n.plot(label=f\"Net ({viz_bps} bps)\")\n",
        "plt.title(\"Long–Short Top–Bottom — Equity Curve\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Growth of $1\")\n",
        "plt.show()\n",
        "\n",
        "# Table: performance by cost\n",
        "res_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae1004bd",
      "metadata": {
        "id": "ae1004bd"
      },
      "source": [
        "### Turnover Diagnostics\n",
        "High turnover strategies are more sensitive to costs. We show average and distribution of turnover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82bef5b",
      "metadata": {
        "id": "f82bef5b"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Average one-way turnover (monthly):\")\n",
        "print(pd.DataFrame({\n",
        "    \"Long-Only\": [to_long.mean()],\n",
        "    \"Long–Short\": [to_ls.mean()]\n",
        "}))\n",
        "\n",
        "plt.figure()\n",
        "to_long.plot()\n",
        "plt.title(\"Long-Only Turnover (Monthly)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"One-way turnover\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "to_ls.plot()\n",
        "plt.title(\"Long–Short Turnover (Monthly)\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"One-way turnover\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f446747e",
      "metadata": {
        "id": "f446747e"
      },
      "source": [
        "## 7. Discussion & Next Steps\n",
        "**What to write in your GitHub README today (2–4 sentences):**\n",
        "- _Example_: “I tested a standard 12–1 cross-sectional momentum strategy on a liquid US universe with monthly rebalancing. Net performance is highly sensitive to transaction costs; at ~25 bps round-trip, Sharpe drops by X% and CAGR by Y%. Long–short is more cost‑fragile due to higher turnover. Next, I’ll explore slower signals (e.g., 6–12M) and turnover-aware weighting to improve net-of-cost results.”\n",
        "\n",
        "**Extensions you can add tomorrow:**\n",
        "- **Signal robustness**: try different lookbacks (3, 6, 9, 12 months) and skip windows (0–2 months).\n",
        "- **Turnover control**: add a “do-nothing band” (only trade if rank change exceeds a threshold).\n",
        "- **Risk control**: equal risk contribution (vol targeting) vs. equal weight.\n",
        "- **Universe sanity**: filter by ADV/volume; drop illiquid names, or cap position sizes.\n",
        "- **Lead–lag**: relate high momentum deciles’ returns to sector ETFs to see diffusion effects."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}